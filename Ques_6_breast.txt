import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import accuracy_score

d = load_breast_cancer()
x = d.data
y = d.target
d
df = pd.DataFrame(x, columns=d.feature_names)
df


scaler = StandardScaler()
std = scaler.fit_transform(x)
std


# Agglomerative clustering
agg_clustering = AgglomerativeClustering(n_clusters=2)
y_pred = agg_clustering.fit_predict(std)
ac=accuracy_score(y,y_pred)
print("Accuracy Score - Agglomerative Hierarchical Clustering:", ac*100)


plt.scatter(std[:, 0], std[:, 1], c=y_pred)
plt.title('Agglomerative Hierarchical Clustering (For Sepal Length and Sepal Width)')
plt.xlabel('Mean Radius (Standardized)')
plt.ylabel('Mean Texture (Standardized)')
plt.colorbar()
plt.show()

z = linkage(std, method='ward')
z

plt.figure(figsize=(12, 6))
dendrogram(z)
plt.xlabel('Values')
plt.ylabel('Distance')
plt.title('Hierarchical Clustering Dendrogram')
plt.show()


#K-means
from sklearn.cluster import KMeans

cluster_sizes = range(1, 569)
sse = []
for k in cluster_sizes:
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(std)
    sse.append(kmeans.inertia_)


plt.plot(cluster_sizes, sse, marker='*')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.show()

cluster_sizes = range(1, 10)
sse = []
for k in cluster_sizes:
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(std)
    sse.append(kmeans.inertia_)


plt.plot(cluster_sizes, sse, marker='*')

plt.xlabel('Number of clusters (K)')
plt.ylabel('Sum of Squared Errors (SSE)')
plt.show()


optimal_k =2
k_opt = KMeans(n_clusters=2)
k_opt.fit(std)


plt.figure(figsize=(12, 6))
cluster_names = {0: "Malignant", 1: "Benign"}

for i in range(optimal_k):
    plt.scatter(std[k_opt.labels_ == i, 0], std[k_opt.labels_ == i, 1],label=cluster_names[i])

plt.scatter(k_opt.cluster_centers_[:, 0], k_opt.cluster_centers_[:, 1], s=300, c='red', marker='*', label='Centroids')
plt.title('KMeans Clustering of Iris Dataset')
plt.xlabel('Mean Radius (cm)')
plt.ylabel('Mean Texture (cm)')
plt.legend()
plt.show()




DBSCAN
nn = NearestNeighbors(n_neighbors=2)
nn.fit(std)
distances, _ = nn.kneighbors(std)
distances = np.sort(distances[:,1])
plt.plot(distances)
plt.xlabel("Points sorted by distance")
plt.ylabel("Distance to 2nd nearest neighbor")
plt.title("Knee Point for DBSCAN")
plt.show()
eps = 0.8
min_samples = 5
metric = 'euclidean'

dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric="euclidean")
labels = dbscan.fit_predict(std)

plt.figure(figsize=(12, 6))
cluster_names = {0: "Malignant", 1: "Benign"}
plt.scatter(std[:,0], std[:,1], c=labels,label=cluster_names[i])
plt.xlabel("Mean Radius (cm)")
plt.ylabel("Mean Texture (cm)")
plt.title("DBSCAN Clustering")
plt.colorbar(label="Cluster Label")
plt.show()
